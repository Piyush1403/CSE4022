{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Class notebook 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Installing NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', 'was', 'among', 'these', 'that', 'Hinkle', ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories = 'humor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inaugral corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts= [\"\"\"Fellow-Citizens of the Senate and of the House of Representatives:\n",
    "Among the vicissitudes incident to life no event could have filled me with greater \n",
    "anxieties than that of which the notification was transmitted by your order, \n",
    "and received on the 14th day of the present month.\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Fellow-Citizens', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Senate', 'NNP'), ('and', 'CC'), ('of', 'IN'), ('the', 'DT'), ('House', 'NNP'), ('of', 'IN'), ('Representatives', 'NNPS'), (':', ':'), ('Among', 'IN'), ('the', 'DT'), ('vicissitudes', 'NNS'), ('incident', 'NN'), ('to', 'TO'), ('life', 'NN'), ('no', 'DT'), ('event', 'NN'), ('could', 'MD'), ('have', 'VB'), ('filled', 'VBN'), ('me', 'PRP'), ('with', 'IN'), ('greater', 'JJR'), ('anxieties', 'NNS'), ('than', 'IN'), ('that', 'DT'), ('of', 'IN'), ('which', 'WDT'), ('the', 'DT'), ('notification', 'NN'), ('was', 'VBD'), ('transmitted', 'VBN'), ('by', 'IN'), ('your', 'PRP$'), ('order', 'NN'), (',', ','), ('and', 'CC'), ('received', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('14th', 'JJ'), ('day', 'NN'), ('of', 'IN'), ('the', 'DT'), ('present', 'JJ'), ('month', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    sentences = sent_tokenize(text, language='english')\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence, language='english')\n",
    "        tagged_words = pos_tag(words, lang='eng')\n",
    "        print(tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = nltk.corpus.cmudict.entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133737"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('abdication', ['AE2', 'B', 'D', 'IH0', 'K', 'EY1', 'SH', 'AH0', 'N'])\n",
      "('abdnor', ['AE1', 'B', 'D', 'N', 'ER0'])\n",
      "('abdo', ['AE1', 'B', 'D', 'OW0'])\n",
      "('abdollah', ['AE2', 'B', 'D', 'AA1', 'L', 'AH0'])\n",
      "('abdomen', ['AE0', 'B', 'D', 'OW1', 'M', 'AH0', 'N'])\n",
      "('abdomen', ['AE1', 'B', 'D', 'AH0', 'M', 'AH0', 'N'])\n",
      "('abdominal', ['AE0', 'B', 'D', 'AA1', 'M', 'AH0', 'N', 'AH0', 'L'])\n",
      "('abdominal', ['AH0', 'B', 'D', 'AA1', 'M', 'AH0', 'N', 'AH0', 'L'])\n",
      "('abduct', ['AE0', 'B', 'D', 'AH1', 'K', 'T'])\n",
      "('abducted', ['AE0', 'B', 'D', 'AH1', 'K', 'T', 'IH0', 'D'])\n",
      "('abducted', ['AH0', 'B', 'D', 'AH1', 'K', 'T', 'IH0', 'D'])\n",
      "('abductee', ['AE0', 'B', 'D', 'AH2', 'K', 'T', 'IY1'])\n",
      "('abductees', ['AE0', 'B', 'D', 'AH2', 'K', 'T', 'IY1', 'Z'])\n",
      "('abducting', ['AE0', 'B', 'D', 'AH1', 'K', 'T', 'IH0', 'NG'])\n",
      "('abducting', ['AH0', 'B', 'D', 'AH1', 'K', 'T', 'IH0', 'NG'])\n",
      "('abduction', ['AE0', 'B', 'D', 'AH1', 'K', 'SH', 'AH0', 'N'])\n",
      "('abduction', ['AH0', 'B', 'D', 'AH1', 'K', 'SH', 'AH0', 'N'])\n",
      "('abductions', ['AE0', 'B', 'D', 'AH1', 'K', 'SH', 'AH0', 'N', 'Z'])\n",
      "('abductions', ['AH0', 'B', 'D', 'AH1', 'K', 'SH', 'AH0', 'N', 'Z'])\n",
      "('abductor', ['AE0', 'B', 'D', 'AH1', 'K', 'T', 'ER0'])\n"
     ]
    }
   ],
   "source": [
    "for entry in entries[100:120]:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('boat.n.01'), Synset('gravy_boat.n.01'), Synset('boat.v.01')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('boat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import  stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('french')[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = TweetTokenizer()\n",
    "text = \"those of you around the world who canno take up Harper Collins on their Free #lolol wow this is grt lmao lol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['those',\n",
       " 'of',\n",
       " 'you',\n",
       " 'around',\n",
       " 'the',\n",
       " 'world',\n",
       " 'who',\n",
       " 'canno',\n",
       " 'take',\n",
       " 'up',\n",
       " 'Harper',\n",
       " 'Collins',\n",
       " 'on',\n",
       " 'their',\n",
       " 'Free',\n",
       " '#lolol',\n",
       " 'wow',\n",
       " 'this',\n",
       " 'is',\n",
       " 'grt',\n",
       " 'lmao',\n",
       " 'lol']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Port_stemmer = PorterStemmer()\n",
    "Snow_stemmer = SnowballStemmer(\"english\")\n",
    "Lancaster_stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Port_stemmer.stem('unhappy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter : dye\n",
      "Snowball : dye\n",
      "Lancaster : dye\n",
      "\n",
      "\n",
      "Porter : dye\n",
      "Snowball : dye\n",
      "Lancaster : dye\n",
      "\n",
      "\n",
      "Porter : tile\n",
      "Snowball : tile\n",
      "Lancaster : til\n",
      "\n",
      "\n",
      "Porter : tile\n",
      "Snowball : tile\n",
      "Lancaster : til\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_of_words = ['dye', 'dyeing', 'tile', 'tiling']\n",
    "for word in list_of_words:\n",
    "    print(\"Porter : \" + Port_stemmer.stem(word))\n",
    "    print(\"Snowball : \" + Snow_stemmer.stem(word))\n",
    "    print(\"Lancaster : \" + Lancaster_stemmer.stem(word))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
